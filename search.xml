<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[DNS解析]]></title>
    <url>%2F2019%2F09%2F12%2FDNS%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[DNS概述域名系统：互联网上主机/路由器的识别问题： IP地址 域名： www.baidu.com 多层命名服务器构成的分布式数据库 DNS服务： 域名向IP地址的翻译 主机别名 邮件服务器别名 负载均衡：Web服务器 DNS域名解析过程 当一个用户在浏览器中输入www.baidu.com时，DNS解析主要有以下几个步骤： 浏览器检查缓存中有没有这个域名对应的解析过的IP，如果缓存命中，解析结束；未命中，进入下个阶段。（浏览器的缓存大小和缓存时间都是有限制的） 查找操作系统缓存中是否有这个域名对应的DNS解析结果。缓存命中，解析结束。未命中，进入下个阶段（在Windows中可以通过C:Windows\System32\drivers\etc\hosts查看）; 如果本地缓存无法完成，那么就会把这个域名发送到LDNS（本地域名服务器），如果在学校接入互联网，那么LNDS就在学校；如果在小区接入互联网，那么这个LDNS就是接入互联网的应用提供商，即电信或联通。 这个域名服务器的性能很好，缓存时间受域名的失效时间限制，不受缓存空间的限制。大约80%的域名解析都到这里就完成了。故LDNS承担了主要的域名解析工作; 如果LDNS仍然没有命中，就直接到Root Server域名服务器请求解析； 根域名服务器返回给本地域名服务器一个所查询的顶级域名服务器。顶级域名服务器包括.com, .cn, .org等。全球有十三台根域名服务器。 本地域名服务器再向上一步返回的顶级域名服务器发送请求； 接受请求的顶级域名服务器查找并返回此域名对应的权威域名服务器的地址。 权威域名服务服务器会查询存储的域名和IP的映射关系表，在正常情况下根据域名得到IP地址，连同一个TTL值返回给LDNS域名服务器。 LDNS缓存这个域名和IP，缓存的时间由TTL控制。 把解析的结果返回给用户，用户根据TTL值缓存在本地系统缓存中，域名解析结束。 Note：本地域名服务器也能够缓存顶级域名服务器的地址，因而允许本地DNS绕过查询链中的根域名服务器。 主机向LDNS查询是递归查询，LDNS向根域名服务器查询是迭代查询。 互联网的域名结构： DNS缓存：只要域名解析服务器获得域名-IP映射，即缓存这一映射。一段时间过后，缓存条目失效。本地域名服务器一般会缓存顶级域名服务器的映射，因此根域名服务器不经常别访问。有效时间（两天） DNS可以使用UDP或者TCP进行传输，使用的端口号都为53.大多数情况下DNS使用UDP进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用TCP进行传输： 返回的响应超过512字节（UDP）最大支持512字节； 区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据） DNS记录和消息格式实现DNS分布式服务器的所有DNS服务器共同存储了资源记录，RR提供了主机名到IP地址的映射。 资源记录（RR）包含了四个字段：name，value，type，ttl TTL是该记录的生存时间，它决定了资源记录应当从缓存中删除的时间。Name和Value的值取决于Type： 如果Type=A，则Name是主机域名，Value是该主机域名对应的IP地址。例如(relay.bar.foo.com, 145.37.93.126, A)就是一条类型A的记录。 如果Type=NS，则Name是个域（如foo.com），而Value是知道如何获得该域中主机地址的权威DNS服务器的主机域名。简单来说就是由哪个DNS服务器对该域名进行解析，如（foo.com, dns.foo.com, NS)是一条类型NS的记录。 如果Type=CNAME，Name是某一真实域名的别名，Value是真实域名。简称别名解析，例如(foo.com, relay.bar.foo.com, CNAME)就是一条CNAME类型的记录。 如果Type=MX，Value是与name相对应的邮件服务器的域名。（foo.com, mail.bar.foo.com, MX）就是一条MX记录。 概要如下表所示： 类型 功能 A 将域名指向一个 IPv4 地址 NS 将子域名指向其它 DNS 服务器解析 CNAME 将域名指向另一个域名 MX 将域名指向邮件服务器地址]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>DNS解析</tag>
        <tag>DNS缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信的各种方式及比较]]></title>
    <url>%2F2019%2F09%2F02%2F%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%E7%9A%84%E6%96%B9%E5%BC%8F%E5%92%8C%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[进程间通信的各种方式进程间通信的方法包括管道(PIPE)、消息队列、信号、共享内存以及套接字(Socket)。 一、管道管道通常指无名管道，是UNIX系统IPC最古老的形式。 特点： 半双工（数据只能单向流动），具有固定的读端和写端 只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系 也可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write函数，但它不是普通的文件。 单个进程的管道几乎没有任何用处。所以，通常调用pipe的进程接着调用fork，这样就创建了父进程与子进程之间的IPC通道。 如果数据从父进程流向子进程，则关闭父进程的读端(fd[0])与子进程的写端(fd[1]);反之，可以使数据流从子进程流向父进程。 二、FIFO 命名管道FIFO，也称为命名管道，是一种文件类型。 特点： FIFO可以在无关的进程之间交换数据，与无名管道不同 FIFO有路径名与之关联，以一种特殊设备文件形式存在于文件系统中。 FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO同时清除数据，并且“先进先出”。 三、消息队列消息队列，是消息的链接表，存放在内核中。一个消息队列有一个标志符（即队列ID）来标识。 特点： 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。 四、信号量信号量是一个计数器，信号量用于实现进程间的同步与互斥，而不是存储进程间通信数据。 信号量可以用来控制多个进程对共享资源的访问。若此信号量的值为正，则进程可以使用该资源；进程将信号量减一，表示其使用了一个资源单元。若此信号量的值为0，则进程进入休眠状态，直至信号量位于0.若一个进程不再使用由一个信号量控制的共享资源时，该信号值增1.如果有进程正在休眠等待此信号量，则唤醒它们。 特点： 信号量用于进程间资源的同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的PV操作，程序对信号量的操作都是原子操作。 支持信号量组。 五、共享内存共享内存，指两个或多个进程共享一个给定的存储区。 特点： 共享内存是最快的一种IPC，因为进程是直接对内存进行存取。 因为多个进程可以同时操作，所以需要同步 信号量+共享内存通常会结合在一起使用，使用信号量用来同步对同享内存的访问。 六、套接字套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器的进程通信。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进程同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP保持登录状态的机制]]></title>
    <url>%2F2019%2F08%2F30%2FHTTP%E4%BF%9D%E6%8C%81%E7%99%BB%E5%BD%95%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[HTTP保持登录状态1. 无状态的HTTP协议HTTP无状态是指：HTTP协议对事物处理是没有记忆能力的，也就是说服务器不知道客户端是什么状态。当我们向服务器发送请求后，服务器解析此请求，然后返回对应的响应，服务器负责完成整个过程。这个过程是独立的的，服务器不会记录前后状态的变化，也就是缺失状态记录。这就是说如果后续处理需要前面的信息，就必须重传，这导致需要额外传递一些前面的重复请求，才能获取后续响应，然而这种效果显然太浪费资源了。于是两种用于保持HTTP连接状态的技术就出现了，即Session和Cookies。Session在服务端，也就是网站的服务器，用来保存用户的会话信息；Cookie在客户端，有了Cookies，浏览器在下次访问网站是会自动附带上它发送给服务器，服务器通过识别Cookies鉴别出是哪个用户，判断是否是登录状态，然后返回对应的响应。 Cookies保存了登录的凭证，有了它，只需要在下次请求中携带Cookies发送请求就不用重新输入用户名，密码等信息重新登录了。所以在爬虫中，一般会将登录成功后获取的Cookies放在请求头中直接请求，而不必重新模拟登录。 2. 原理剖析SessionSession指有始有终的一系列动作/消息。比如，打电话时，从拿起电话拨号到挂断电话这一过程可以称为一个Session。 而Web中，Session对象用来存储特定用户Session所需的属性和配置信息。这样，当用户在各个Web网页之间跳转时，存储在Session对象的变量不会丢失，而是在整个Session中一直存在下去。当用户请求来自应用程序的web网页时，如果该用户还没有Session，则web服务器会自动创建一个Session对象。而当Session过期或被放弃的时候，服务器就会终止该Session。 CookiesCookies指某些网站为了辨别用户身份，进行Session跟踪而存储在本地终端上的数据。 当客户端第一次请求服务器时，服务器会返回一个请求头中带有Set-Cookie的字段相应给客户端，用来标记是哪个用户，客户端会把Cookies保存起来，Cookies携带了SessionID信息，服务器检查该Cookies即可查找到对应的Session是什么，然后再判断Session来以此辨别用户状态。 成功登录某个网站时，服务器会告诉客户端设置哪些Cookies信息，在后续访问客户端会把Cookies发送给服务器，服务器再找到对应的Session加以判断。如果Session中某些设置登录状态是有效的，就证明用户处于登录状态，此次返回登录之后才可以查看网页内容，浏览器进行解析，用户就可以看到内容了。 3. Cookies内容 name 该Cookies的名称，一旦创建，名称不可更改 Value 该Cookie的值，如果值是Unicode字符，需要为字符编码，如果是二进制数据，则需要BASE64编码 Domain：可以访问该Cookie的域名。如果设置为12306.com，则所有以12306.com结尾的域名都可以访问该Cookie。 Max age:该Cookie失效的时间，单位为秒, 常与Expires一起使用。Max age如果是正数，则该Cookie在Max Age秒后失效。如果为负数，则关闭浏览器时Cookie失效。浏览器也不会以任何形式保存该Cookie。 Path：该Cookie的使用路径。如果设置为/path/，则只有路径为/path/的页面可以访问该Cookie。如果设置为/，则本域名下所有页面都可以访问该Cookie。 Size：该Cookie的大小。 HTTP字段：Cookie的httponly属性。若此属性的值为true，则只用在HTTP头带有此Cookie信息，而不能通过document.cookie来访问此Cookie。 Secure:该Cookie是否仅被使用安全协议传输。安全协议有HTTPS和SSL等，在网络上传输数据前先将数据加密。默认为false。 4.常见误区会话Cookie和持久Cookie传说中会话Cookie是把Cookie放在浏览器内存中，浏览器关闭后该Cookie失效，持久Cookie则会保持到客户端的硬盘中，下次还可以继续使用，长久保持用户登录状态。 传说是假的，过期时间是由Cookie的Max Age或Expire决定的。持久化Cookie是把有效时间设置的比较长，这样下次访问时仍然携带之前的cookie，就可以直接保持登录状态。 Session误区对于Session来说，除非程序员通知服务器删除Session，否则服务器会一直保留。 但是在我们关闭浏览器后，浏览器不会主动关闭之前通知服务器它将要关闭，所以服务器不会有机会知道浏览器已经关闭。 大部分Session机制使用会话Cookis来保存SessionID信息，而关闭浏览器后，Cookies消失了，再次连接服务器时，就无法找到原来的Session了。如果服务器设置的Cookies被浏览器保存到硬盘上，或者用某种手段改写浏览器发出HTTP请求头把原来的Cookies发送给服务器，则当再次打开服务器是，仍然能够找到原来的SessionID，仍然可以保存登录状态。 由于关闭浏览器不会使Session被删除，这就需要服务器为Session设置一个失效时间，当距离客户端上一次使用Session的时间超过这个失效时间时，服务器就认为客户端停止了活动，会把Session删除以节省存储空间。 参考[1] Session和Cookies的原理及代码实现]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>Session</tag>
        <tag>Cookies</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB中的事务隔离级别和锁的关系]]></title>
    <url>%2F2019%2F08%2F19%2F%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8E%E9%94%81%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[InnoDB中的事务隔离级别和锁的关系一次封锁or两段锁因为有大量的并发访问，为了预防死锁，一般应用中推荐一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不使用，因为在事务开始阶段，数据库并不知道会用到哪些数据。 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁和解锁阶段（因此叫两段锁）： 加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其他事务可以继续加共享锁，但不能加排它锁）,在进行写操作之前要申请并获得X锁（排他锁，其他事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。 解锁阶段：当事务释放了一个封锁之后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。 事务 加锁/解锁处理 begin; insert into test… 加insert对应的锁 update test set… 加update对应的锁 delete from test… 加delete对应的锁 commit 事务提交时，同时释放insert、update、delete对应的锁 这种方式虽然无法避免死锁，但是两段锁协议可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候） 事务中的加锁方式四种隔离级别在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。我们的数据库锁，也是为了构建这些隔离级别存在的。 锁的种类MySQL中常见的有表锁和行锁，也有新加入的元数据锁(meta data lock MDL)等，表锁是对一整张表加锁虽然可分为读锁和写锁，但毕竟是锁住整张表，会导致并发能力下降，一般是做ddl处理时使用。 行锁则是锁住数据行，这种加锁方法比较复杂，但是由于只锁住有限的数据，对于其他数据不加限制，所以并发能力强，MySQL一般都是用行锁来处理数据，这里主要讨论行锁。 Read Committed（读取提交内容）在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改是需要加锁的。 为了防止并发过程中的修改冲突，事务A中MySQL给teacher_id=1的数据行加锁，并一直不commit（释放锁），那么事务B也就一直拿不到该行锁，wait直到超时。 但是我们注意到，teacher_id是有索引的，如果是没有索引的class_name呢，那么MySQL会给整张表的所有数据行加行锁，这听起来有点不可思议，但是当SQL运行的过程中，MySQL并不知道哪些数据行是class_name=”初三一班“，如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL_Server层进行过滤。 但在实际使用过程中，MySQL做了一些改进，在MySQL_Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁（违背了二段锁的约束）,这样做，保证了最后只有持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见即使MySQL，为了效率也是会违反规范的。 这种情况同样适用于MySQL的默认隔离级别RR。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。 Repeatable Read(可重读)这是MySQL中InnoDB默认的隔离级别。我们姑且分为”读“和”写“两个模块来讲解。 读读就是可重读，可重读这个概念是一事务的多个实例在并发读取数据时，会看到相同的数据行，有点抽象。 不可重复度和幻读的区别很多人搞不清楚不可重复读和幻读的区别，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。 如果使用锁机制来实现这两种隔离级别，在可重复读中，该SQL第一次读取到数据后，就将这些数据加锁，其他事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还有可以insert数据提交，这是事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效避免幻读、不可重复读、脏读等，但会极大的降低数据库的并发能力。 所以说不可重复度和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题。 上文说的是，是使用悲观锁机制来处理这两种问题，但是MySQL、ORACLE、PostgreSQL等成熟的数据库，处于性能考虑，都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来避免这种问题。 悲观锁和乐观锁 悲观锁 正如其名，它指的是对外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其他事务无法修改这些数据。修改删除数据时也要加锁，其他事务无法处读取这些数据。 乐观锁 相对悲观锁而言，乐观锁采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据的锁机制实现，以保证操作最大程度的独占性。但随着而来就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。 而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本的记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个字段“version”来实现。读取此数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行对比，如果提交的版本号大于数据表当前版本号，则予以更新，否则认为是过期数据。 MVCC在MySQL的InnoDB中的实现在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。在可重读Repeatable reads事务隔离级别下： SELECT时，读取创建版本号&lt;=当前事务版本号，删除版本号为空或&gt;当前事务版本号 INSERT时，保存当前事务版本号为行的创建版本号 DELETE时，保存当前事务版本号为行的删除版本号 UPDATE时，插入一条新记录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来行。 通过MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用，大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行。 在数据库方面的教科书学到，PR是可重复读的，但无法解决幻读，而只有在Serializable级别才能解决幻读。经测试，在MySQL中是不存在这种情况的，在事务C提交后，事务A还是不会读到这条数据。可见在RR级别中，是解决了幻读的问题的。 “读”和“读”的区别事务的隔离级别其实都是对于读数据的定义，但到了这里，就被拆成了读和写两个模块来讲解。这主要是因为MySQL中的读，和事务隔离级别中的读，是不一样的。 在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效性特别敏感的业务中，就很可能出问题。 对于这种读取历史数据的方式，我们叫它快照读，而读取数据库当前版本数据的方式，叫当前读。很显然，在MVCC中： 快照读：即SELECT SELECT * fron table… 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 SELECT * from table where ？lock in share modes; SELECT * from table where ? for update; insert； update； delete; 事务的隔离级别实际上都是定义了当前读的级别，MySQL为了减少锁处理（包括等待其他锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”，就需要另外的模块来解决了。 写（“当前读”）事务的隔离级别虽然只定义了读数据的要求，实际上这也可以说是写数据的要求。上文的“读”,实际上讲的快照读，而这里说的“写”就是当前读了。 为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁。 Next-Key锁Next-key锁是行锁和GAP（间隙锁）的合并，行锁上文已经介绍了，接下来GAP间隙锁。行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题。我们可以看看RR级别和RC级别的对比： RR级别中，事务A在update后加锁，事务B无法插入新数据，这样事务A在update前后读的数据保持一致，避免了幻读，这个锁，就是GAP锁。 不仅用行锁锁住了相应的数据行，同时也在两边的区间，加入了gap锁，这样事务B就无法在这两个区间insert进新数据。 受限于这种实现方式，InnoDB很多时候会锁住不需要锁的区间。 如果使用的是没有索引的字段，那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没用索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其他事务无法插入任何数据。 行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的Next-KEY锁共同解决了RR级别在写数据时的幻读问题。 Serializable这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观的理论，实现简单，数据更加安全，但是并发能力非常差。如果你的业务并发特别少或者没有并发，同时又要求数据及时可靠的话，可以使用这种模式。 注意，不要看到select就说不会加锁了，在Serializable这个级别，还是会加锁的。 参考资料[1] InnoDB中的事务隔离级别与锁的关系]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>事务隔离</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS的建立过程]]></title>
    <url>%2F2019%2F08%2F14%2FHTTPS%2F</url>
    <content type="text"><![CDATA[HTTPS简介HTTP有如下安全性问题： 使用明文进行通信，内容可能会被窃听 不验证通信方的身份，通信方的身份有可能遭遇伪装 无法验证报文的完整性，报文有可能遭篡改。 HTTPS不是新协议，而是让HTTP先和SSL（Secure Socket Layer）通信，再由SSL和TCP通信，也就是说HTTPS使用了隧道进行通信。 通过使用SSL，HTTPS具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改） HTTPS采用混合的加密机制，使用非对称秘钥加密用于传输对称秘钥来保证传输过程的安全性，之后使用对称秘钥加密进行通信来保证通信过程的效率。 数字签名除了加/解密之外，还可以用加密系统对报文进行签名，以说明是谁编写的报文，同时证明报文未被篡改过。这种技术称为数字签名。 使用数字签名有以下两个好处： 签名可以证明是作者编写了这条报文。只有作者才会有最机密的私有秘钥。因此，只有作者才能计算出这些校验和。校验和就像来自作者的个人”签名“一样。 签名可以防止报文被篡改。如果有恶意攻击者在报文传输过程中对其进行了修改，校验和就不再匹配了。由于校验和只有作者保密的私有秘钥才能产生。所以攻击者无法为篡改了的报文伪造出正确的校验码。 下面的例子说明了A是如何向节点B发送一条报文，并对其进行签名的。 节点A将变长报文用哈希函数提取出定长的摘要 节点A对摘要应用了一个“签名”函数，这个函数以用户的私有秘钥作为参数，因为只有用户才知道私有秘钥，所以正确的签名函数会说明签名者就是其所有者。 一旦计算出签名，节点A就将其附加在报文的末尾，并将报文和签名都发送给B。 在接收端，如果节点B需要确定报文确实是节点A发出的，而且没有被篡改过，节点B就可以对签名进行检查。节点B接收经私有秘钥加密的签名，使用公钥解密，得到拆包后的摘要。由此证明，报文的确是由A发出的。B再对信件使用哈希函数，将得到的结果与节点B解密的摘要版本作对比，如果匹配，说明这封信未修改过。 证书公钥存在伪装的问题，通过使用数字证书来对公钥进行认证。 数字证书认证机构（CA）是客户端与服务器双方都可信赖的第三方机构。 服务器的运营人员向CA提出公开秘钥的申请，CA在判明申请者的身份之后，会对已申请的公开密钥做数字签名，具体过程如下：CA用自己的私钥对服务器申请的公钥已以及相关信息加密，生成数字证书，然后将这个公开秘钥和数字签名发送给服务器。进行HTTPS通信时就多了一个步骤： 服务器发送请求时，在签名的同时，附上自己的数字证书； 客户端收到请求后，用CA的公钥解开数字证书，得到其中服务器的公开秘钥； 客户端用得到的公钥对数字签名进行验证，如果验证通过了，就可以开始通信了。 HTTPS的通信过程 由上图可知，HTTPS的通信过程主要分为以下几个步骤： 客户端向服务端发送请求； 服务端用将本身的数字证书发送给客户端； 客户端用自己的CA（主流的CA机构证书一般都内置在各个主流浏览器中)公钥去解密证书，如果证书有问题会提示风险 如果证书没问题，客户端会生成一个对称加密的随机秘钥然后再用刚刚解密的服务器端公钥对数据进行加密，然后发送给服务器 服务器收到以后用自己的私钥对客户端发来的对称秘钥进行解密 之后双方就拿着这个对称加密秘钥来进行正常的通信]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap和ConcurrentHashMap]]></title>
    <url>%2F2019%2F08%2F13%2FHashMap%E5%92%8CConCurrentHashMap%2F</url>
    <content type="text"><![CDATA[HashMap源码分析 Map这样的Key Value在软件开发中是非常经典的结构，常用于在内存中存放数据。 HashMap众所周知HashMap底层是基于数组+链表组成的，不过jdk1.7和1.8中实现稍有不同，为了便于理解，以下源码分析以JDK1.7为主 存储结构内部包含了一个Entry类型的数组table。 1transient Entry[] table; Entry存储着键值对。它包含了四个字段，从next字段我们可以看出来Entry是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。HashMap使用拉链法来解决冲突，同一个链表存放哈希值和散列桶取模运算结果相同的Entry。 下面是1.7中的实现。 123456789101112131415161718192021222324252627282930313233343536static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K, V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n)&#123; value = v; key = k; next = n; hash = h; &#125; public final K getKey()&#123; return key; &#125; public final boolean equals(Object o)&#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if(k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2)))&#123; Object v1 = getValue(); Object v2 = e.getValue(); if(v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode()&#123; return Object.hashCode(getKey()) ^ Object.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125;&#125; 拉链法的工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put("K1", "V1");map.put("K2", "V2");map.put("K3", "V3"); 新建一个HashMap，默认大小为16； 插入&lt;K1, V1&gt;键值对，先计算K1的hashCode为115，使用除留余数法得到所在的桶下标115%16=3 插入&lt;K2, V2&gt;键值对，先计算K2的hashCode为118，使用除留余数法达到所在的桶下标118%16=6； 插入&lt;K3, V3&gt;键值对，计算K3的hashCode为118，使用除留余数法得到所在的桶下标118%16=6，插在&lt;K2,V2&gt;前面。 这里应该注意到链表的插入是以头插法进行的。例如上面的&lt;K3,V3&gt;不是插在&lt;K2,V2&gt;后面，而是插入在链表头部。 查找需要分成两步进行： 计算键值所在的桶 在链表上循序查找，时间复杂度显然与链表的长度成正比 HashMap核心成员变量123456789101112131415static final int DEFAULT_INITIAL_CAPACITY = 1&lt;&lt;4;static final int MAXMUM_CAPACITY = 1&lt;&lt;30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final Entry&lt;?,?&gt; [] EMPTY_TABLE = &#123;&#125;;transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;transient int size;int threshold;final float loadFactor; 初始化桶大小，因为底层是数组，所以这是数组默认的大小，16(索引0~15); 桶的最大值，2^30； 默认的负载因子（0.75）； table是真正存放数据的数组； size是Map的真实存放元素数量； threshold，桶大小可在初始化时显式指定； 负载因子，可在初始化时显示指定。 给定的默认容量为16，负载因子为0.75.Map在使用过程中不断的往里面存放数据，当数量达到了16*0.75=12时，就需要将当前16的容量进行扩容。而扩容这个操作设计rehash、复制数据等操作，所以非常消耗性能。 因此通常建议能提前预估HashMap的大小，尽量的减少扩容带来的性能损耗。 知晓了基本结构，下面来看看重要的put和get操作。 put操作1234567891011121314151617181920212223242526public V put(K key, V value)&#123; //判断当前数组是否需要初始化 if(table == EMPTY_TABLE)&#123; inflateTable(threshold); &#125; //键为空时单独处理 if(key == null) return putForNullKey(value); int hash = hash(key); //确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为key的键值对，如果存在的话就更新这个键值对的值为value，并返回原来的值 for(Entry&lt;K, V&gt; e = table[i]; e != null; e=e.next)&#123; Object k; if(e.hash == hash &amp;&amp; ((k=e.key) == key || key.equals(k)))&#123; V oldValue = e.valu; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //插入新键值对 addEntry(hash, key, value, i); return null;&#125; HashMap允许插入键为null的键值对，但是因为无法调用null的hashCode()方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap使用第0个桶存放键为null的键值对。 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 12345678910111213141516void addEntry(int hash, K key, V value, int bucketIndex)&#123; //判断是否需要扩容 if((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex]))&#123; //如果需要就进行两倍扩容，并将当前的key重新hash并定位 resize(2 * table.length); hash = (null != key)?hash(key):0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, buckeyIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex)&#123; Entry&lt;K,V&gt; e = table[bucketIndex]; //头插法，链表头部指向新的键值对，将当前位置的桶传入新建的桶中。 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; get操作123456789101112131415161718192021public V get(Object key)&#123; if (key == null)&#123; return getForNullKey(); &#125; Entry&lt;K, V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key)&#123; if(size == 0)&#123; return null; &#125; int hash = (key == null)? 0:hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next)&#123; Object k; if(e.hash == hash &amp;&amp; ((k = e.key) == key) || (key != null) &amp;&amp; key.equals(k)) return e; &#125; return null;&#125; 首先根据key计算出hashCode，然后定位到具体的桶中； 判断该位置是否为链表； 不是链表就根据key，key的hashCode是否相等来返回值； 为链表则需要遍历直到key及hashCode相等时就返回值 啥都没取到就直接返回null。 put操作中的一些小心机计算hash值123456789101112131415final int hash(Object k)&#123; int h = hashSeed; if (0 != h &amp;&amp; k instaceof String)&#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashcode(); //类似于扰动函数 h ^= (h&gt;&gt;&gt;20) ^(h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^(h &gt;&gt;&gt; 4);&#125;public final int hashCode()&#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; 取模另x=1&lt;&lt;4,即x为2的四次方，它具有以下性质： 12x : 0001 0000x-1: 0000 1111 令一个数y与x-1做与运算，可以去除y位级表示的第四位以上数： 123y : 1011 0010x-1 : 0000 1111y&amp;(x-1): 0000 0010 这个性质和y对x取模效果是一样的。我们知道，位运算的代价比求模运算小得多，因此在这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将key的hash值对桶个数取模：hash%capacity，如果能保证capacity为2的n次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length)&#123; return h &amp; (length-1);&#125; 扩容基本原理设HashMap的table长度为M，需要存储的键值对数量为N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为N/M，因此平均查找次数的复杂度为O(N/M). 为了让查找的成本降低，应该尽可能使得N/M尽可能小，因此需要保证M尽可能大，也就是说table要尽可能大。HashMap采用动态扩容来根据当前的N值来调整M值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数有：capacity，size，threshold和load_factor。 参数 含义 capacity table的容量大小，默认为16。capacity必须保证为2的n次方 size 键值对的数量 threshold size的临界值，当size大于等于threshold就必须进行扩容操作 load_factor 装载因子，table能够使用的比例，threshold=capacity*load_factor 当需要扩容时，令capacity为原来的两倍。扩容使用resize()实现，需要注意的是，扩容操作同样需要把oldTable的所有键值对重新插入到newTable中，因此这一步是非常费时的。 1234567891011121314151617181920212223242526272829void resize(int newCapacity)&#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if(oldCapacity == MAXIMUM_CAPACITY)&#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable)&#123; Entry[] src = table; int newCapacity = newTable.length; for(int j=0; j&lt;src.length; j++)&#123; Entry&lt;K,V&gt; e = src[j]; if(e != null)&#123; src[j] = null; do&#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125;while(e != null); &#125; &#125;&#125; 扩容-重新计算桶下标在进行扩容时，需要把键值对重新放到对应的桶上。HashMap使用了一个特殊的机制。可以降低重新计算桶下标的操作。假设源数组长度为capacity为16，扩容之后new capacity为32. 12capacity : 0001 0000newCapacity: 0010 0000 对于一个key， 如果它的哈希值如果在第五位上为零，那么取模得到的结果和之前一样。 如果为1，那么得到的结果为原来的结果+16. 计算数组容量HashMap构造函数允许用户传入的容量不是2的n次方，因为它可以自动地将传入的容量转换为2的n次方。先考虑如何求一个数的掩码，对于10010000，它的掩码为11111111，可以使用如下方法得到： 123mask |= mask &gt;&gt; 1 1101 1000mask |= mask &gt;&gt; 2 1111 1110mask |= mask &gt;&gt; 4 1111 1111 mask+1是大于原始数字的最小的2的n次方。 12num 1001 0000mask+1 10000 0000 一下是HashMap中计算数组容量的代码： 12345678910static final int tableSizeFor(int cap)&#123; //为了避免cap本来就是2的n次方的情况 int n = cap -1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n&lt;0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n +1;&#125; Base 1.81.7有一个很明显需要优化的点，当Hash冲突严重时，在桶上形成的链表会变得越来越长，这样在查询时的效率就会越来越低；时间复杂度为O(N). 因此1.8中重点优化了这个查询效率 和1.7大体上都差不多，有几个重要的区别： TREEIFY_THRESHOLD = 8, 用于判断是否需要将链表转换为红黑树的阈值； HashEntry修改为Node。 Node的核心组成和HashEntry一样，存放的都是key value hashCode next等数据。 其put操作要比1.7复杂一些： 判断当前桶是否为空， 空的就需要初始化（resize中会判断是否进行初始化） 根据当前key的hashCode定位到具体的桶并判断是否为空，为空表明没有Hash冲突就直接在当前位置创建一个新桶即可。 如果当前桶有值（Hash冲突），那么就要比较当前桶中的key、key的hashCode于写入的key是否相等，相等就复制给e，然后统一返回。 如果当前桶为红黑树，那么就按照红黑树的方式写入数据。 如果是个链表，就需要将当前的key、value封装成一个新节点写入到当前桶的后面（形成链表）。（1.7是头插法） 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到key相同时直接退出遍历 如果e != null 就相当于存在相同的key，那就需要将值覆盖。 最后判断是否需要进行扩容。 get方法： 首先将key hash之后取得所定位的桶。 如果桶为空直接返回null。 否则判断桶的第一个位置（有可能是链表、红黑树）的key是否为查询的key，是就直接返回value。 如果第一个不匹配，则判断它的下一个是红黑树还是链表。 红黑树就按照树的查找方法返回值。 不然就按照链表的方式遍历匹配返回值。 从这两个核心方法可以看出1.8对大链表做了优化，修改为红黑树之后查询效率直接提高到了O(logn). 但是HashMap原有的问题也都存在，比如在并发场景下使用容易出现死循环。 123456789final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();for(int i=0; i &lt; 1000; i++)&#123; new Thread(new Runnable()&#123; @Override public void run()&#123; map.put(UUID.randomUUID().toString(), ""); &#125; &#125;).start();&#125; 在HashMap扩容时会调用resize()方法，这里的并发操作容易在一个桶上形成环形链表；这样当获取一个key时，计算出的index正好是环形链表的下标就会出现死循环。 遍历方式HashMap有以下几种遍历方式： 1234567891011Iterator&lt;Map.Entry&lt;String, String&gt;&gt; entryIterator = map.entryset().iterator();while(entryIterator.hasNext())&#123; Map.Entry&lt;String,String&gt; next = entryItreator.next(); System.out.println("key="+next.getKey() + " value="+next.getValue());&#125;Iterator&lt;String&gt; iterator = map.keySet().iterator();while(iterator.hasNext())&#123; String key = iterator.next(); System.out.printlln("key=" + key + " value="+map.get(key));&#125; 强烈建议使用第一种EntrySet进行遍历。第一种可以把key value同时取出，第二种还得需要通过key去一次value，效率较低。 总结：无论是 1.7 还是 1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至 1.7 中出现死循环导致系统不可用（1.8 已经修复死循环问题）。 下面就可以引入ConcurrentHashMap了。 ConcurrentHashMap源码分析Base1.71.存储结构123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; ConcurrentHashMap和HashMap实现上类似，核心数据如value，以及链表都是由volatile修饰，保证了获取时的可见性。最主要的差别是ConcurrentHashMap采用了分段锁(Segment)，每个分段锁维护者几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是Segment的个数）。一个线程占用所访问一个Segment时，不会影响到其它的Segment。 Segment继承自ReentrantLock。 12345678910111213static final class Segment&lt;K, V&gt; extends ReentrantLock implements Serializable&#123; private static final long serialVersionUID = xxxxxxx; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1?64:1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;&#125;final Segment&lt;K,V&gt;[] segments;static final int DEFAULT_CONCURRENCY_LEVEL = 16; 默认的并发级别为16，也就是说默认创建16个Segment。 2. 用分离锁实现多个线程间的并发写操作在ConcurrentHashMap中，线程对映射表做读操作时，一般情况下不需要加锁就可以完成。对容器做结构性修改的操作才需要加锁。以put操作为例： 首先根据key计算出对应的hash值： 1234567public V put(K key, V value)&#123; int (value == null)&#123; throw new NullPointerException(); &#125; int hash = hash(key.hashCode()); return segmentFor(hash).put(key, hash, value, false);&#125; 然后，根据hash值找到对应的Segment对象。 12345678//使用 key 的散列码来得到 segments 数组中对应的 Segmentfinal Segment&lt;K,V&gt; segmentFor(int hash)&#123; //将散列值右移SegmentShift位，并在高位填充0 //然后把得到的值与SegmentMask做与运算 //从而得到hash值对应的Segment数组的下标值 //最后根据下标值返回散列码对应的Segment对象 return segments[(hash&gt;&gt;&gt; segmentShift) &amp; segmentMask]; &#125; 最后，在这个Segment中执行具体的put操作： 123456789101112131415161718192021222324252627282930313233343536373839V put(K key, int hash, V value, boolean onlyIfAbsent)&#123; //加锁，这里是锁定某个Segment而非整个ConcurrentHashMap lock(); try &#123; int c = count; //如果超过再散列的阈值，执行再散列，table数组的长度扩充一倍 if(c++ &gt; threshold)&#123; rehash(); &#125; HashEntry&lt;K,V&gt;[] tab = table; // 把散列码值与 table 数组的长度减 1 的值相“与” // 得到该散列码对应的 table 数组的下标值 int index = hash &amp; (tab.length-1); //找到散列码对应的具体的那个桶 HashEntry&lt;K, V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key)))&#123; e = e.next; &#125; V oldValue; if(e != null)&#123; //如果键值对已经存在 oldValue = e.value; if(!onlyIfAbsent)&#123; e.value = value; &#125; &#125;else&#123; oldValue = null; // 要添加新节点到链表中，所以 modCont 要加 1 ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; &#125; return oldValue; &#125;finally &#123; unlock(); //解锁 &#125; &#125; 注意： 这里的加锁操作是真的（键的hash值对应的）某个具体的Segment，锁定的是该Segment而不是整个ConcurrentHashMap。因为插入键值对操作只是在Segment包含的某个桶中完成，不需要锁定整个ConcurrentHashMap。此时其他写线程对另外15个Segment的加锁并不会因为当前线程对这个Segment的加锁而阻塞。同时，所有读线程几乎不会因为本线程的加锁而阻塞（除非读线程刚好读到这个 Segment 中某个 HashEntry 的 value 域的值为 null，此时需要加锁后重新读取该值）。 对比HashTable和由同步器包装的HashMap每次只能有一个线程执行读或写操作，ConCurrentHashMap在并发访问性能上有了质的提高。在理想状态下，ConCurrentHashMap可以支持16个线程执行并发写操作（如果并发级别设置为16），及任意数量线程的读操作。 get方法1234567891011121314151617public V get(Object key)&#123; Segment&lt;K,V&gt; s; HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask &lt;&lt; SSHIFT) + SBASE); if (( s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab.s.table) != null)&#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length-1) &amp; h)&lt;&lt; TSHIFT)+TBASE); e != null; e=e.next))&#123; K k; if((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; get逻辑比较简单，只需要将key通过Hash之后定位到具体的Segment，再通过一次Hash定位到具体的元素上。由于HashEntry中value属性是用volatile关键词修饰的，保证了内存可见性，所以每次获取到的都是最新值。 ConCurrentHashMap的get方法是非常高效的，因为整个过程都不需要加锁。 Base 1.81.7已经解决了并发问题，并且能支持N个Segment的并发度，但是依然存在HashMap在1.7版本中的问题，即查询遍历链表效率太低。因此1.8做了一些数据结构上的调整。 底层的数据结构： 同时抛弃了原有的Segment分段锁，而采用了CAS+synchronized来保证并发安全性。 put方法 根据key计算出hashCode； 判断是否需要进行初始化 f即为当前key定位出的Node，如果为空表示当前位置可以写入数据，利用CAS尝试写入，失败则自旋保证成功； 如果当前位置的hashCode == MOVED == -1，则需要进行扩容。 如果都不满足，则利用synchronized锁写入数据。 如果数量大于TREEIFY_THRESHOLD则要转换为红黑树。 get方法 根据计算出来hashCode寻址，如果就在桶上那么就直接返回值。 如果是红黑树那么按照树的额方式获取值。 都不满足就按照链表的方式遍历获取值。 1.8在1.7的数据结构上做了大的改动，采用红黑树之后可以保证查询效率O(logn),甚至取消了ReentrantLock改为了synchronized，这样可以看出在新版的JDK中对synchronized优化是很到位的。 参考资料[1] HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你! [2] 技术面试必备基础知识 ) [3] 探索 ConcurrentHashMap 高并发性的实现机制]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
        <tag>ConcurrentHashMap</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字节跳动18年后端方向笔试真题]]></title>
    <url>%2F2019%2F08%2F12%2F%E5%AD%97%E8%B7%B318%E5%B9%B4%E7%9C%9F%E9%A2%98%2F</url>
    <content type="text"><![CDATA[字跳18年后端方向🥇用户喜好题目描述 为了不断优化推荐效果，今日头条每天要存储和处理海量数据。假设有这样一种场景：我们对用户按照它们的注册时间先后来标号，对于一类文章，每个用户都有不同的喜好值，我们会想知道某一段时间内注册的用户（标号相连的一批用户）中，有多少用户对这类文章喜好值为k。因为一些特殊的原因，不会出现一个查询的用户区间完全覆盖另一个查询的用户区间(不存在L1&lt;=L2&lt;=R2&lt;=R1)。 输入描述 输入： 第1行为n代表用户的个数 第2行为n个整数，第i个代表用户标号为i的用户对某类文章的喜好度 第3行为一个正整数q代表查询的组数 第4行到第（3+q）行，每行包含3个整数l,r,k代表一组查询，即标号为l&lt;=i&lt;=r的用户中对这类文章喜好值为k的用户的个数。 数据范围n &lt;= 300000,q&lt;=300000 k是整型 输入描述 输出：一共q行，每行一个整数代表喜好值为k的用户的个数 问题分析这题的题目很长，容易把人弄晕。给了一个数组，其中索引i对应的值代表员工编号为i的喜好值val；然后给一个查询条件，员工编号的范围[l, r],以及喜好值k，判断在这个范围内有多少喜好值为k的员工。我们输出打印员工的人数即可。 看到这题，就觉得简直不能更简单了好么！用一个数组把员工的喜好值存起来，再用一个for循环遍历索引为[left,right]中的喜好值即可。无奈理想很丰满，现实很骨感，一提交运行就给你一个50%的通过率，原因是超时。可能是员工的人数过多，但喜好值呢，是一个比较固定的范围。 因此想办法改进，很直观的方法是用一个map把喜好和员工编号对应起来，每次查询找到喜好值为k的所有员工，员工的编号是有序的，二分查找所有在范围内的员工即可。二分查找时，找到大于等于员工编号左边界的最小值，和小于等于员工编号的最大值，根据二者的差值求出员工数目。 代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import java.util.*;/** * @author zhen */public class Main &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int N = in.nextInt(); HashMap&lt;Integer, List&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;(); //将喜好为k的员工放在一起 for(int i=1; i&lt;=N; i++)&#123; int k = in.nextInt(); //这种输入方法可以记一下，一个key对应一个列表的情况 List&lt;Integer&gt; tmp = map.getOrDefault(k, new ArrayList&lt;&gt;()); tmp.add(i); map.put(k, tmp); &#125; int q = in.nextInt(); int res = 0; for(int i=0;i&lt;q;i++)&#123; int left = in.nextInt(); int right = in.nextInt(); int target = in.nextInt(); if(map.containsKey(target))&#123; List&lt;Integer&gt; list = map.get(target); //把Integer类型传进去 Integer[] array = list.toArray(Integer[0]); int start = lowerBound(array, target); int end = upperBound(array, target); if(start != -1 &amp;&amp; end != -1)&#123; res = end - start +1; &#125; &#125;else&#123; res = 0; &#125; System.out.println(res); &#125; &#125; //找到大于等于target的最小值 private static int lowerBound(Integer[] array, int target)&#123; int l = 0; int r = array.length-1; while(l &lt;= r)&#123; int mid = (r-l)/2+l; if(target &lt;= array[mid])&#123; r = mid-1; &#125;else&#123; l = mid+1; &#125; &#125; if(l &lt; array.length &amp;&amp; array[l] &gt;= target)&#123; return l; &#125;else&#123; return -1; &#125; &#125; //找到小于等于target的最大值 private static int upperBound(Integer[] array, int target)&#123; int l = 0; int r = array.length-1; while(l &lt;= r)&#123; int mid = (r-l)/2+l; if(target &gt;= array[mid])&#123; l = mid+1; &#125;else&#123; r = mid-1; &#125; &#125; if(r &gt;= 0 &amp;&amp; array[r] &lt;= target)&#123; return r; &#125;else&#123; return -1; &#125; &#125;&#125; 🥈手串题目描述 作为一个手串艺人，有金主向你订购了一条包含n个杂色串珠的手串——每个串珠要么无色，要么涂了若干种颜色。为了使手串的色彩看起来不那么单调，金主要求，手串上的任意一种颜色（不包含无色），在任意连续的m个串珠里至多出现一次（注意这里手串是一个环形）。手串上的颜色一共有c种。现在按顺时针序告诉你n个串珠的手串上，每个串珠用所包含的颜色分别有哪些。请你判断该手串上有多少种颜色不符合要求。即询问有多少种颜色在任意连续m个串珠中出现了至少两次. 输入描述 第一行输入n，m，c三个数，用空格隔开。(1 &lt;= n &lt;= 10000, 1 &lt;= m &lt;= 1000, 1 &lt;= c &lt;= 50) 接下来n行每行的第一个数num_i(0 &lt;= num_i &lt;= c)表示第i颗珠子有多少种颜色。接下来依次读入num_i个数字，每个数字x表示第i颗柱子上包含第x种颜色(1 &lt;= x &lt;= c) 输出描述 一个非负整数，表示该手链上有多少种颜色不符需求。 问题分析这个题目也很绕，搞得人看不明白就对了。我一度觉得自己智商有问题。给一个手串，手串上有n个珠子，总共有c种颜色，每个珠子可能由0种或多种颜色组成，规则为连续m个珠子中出现了至少两次则这种颜色不符合要求。 我们把题目转换一下，有一个数组，索引i指的是颜色i，每个里面放的是所有出现了的珠子位置，然后判断每个颜色里面的珠子是否是符合要求的。 注意：这里要输出的是有多少种颜色不符合需求，因此每种颜色只要出现了一组不符合要求的位置就可以退出了。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.ArrayList;import java.util.LinkedList;import java.util.List;import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int N = in.nextInt(); int M = in.nextInt(); int C = in.nextInt(); List&lt;Integer&gt;[] position = new List&lt;&gt;[C+1]; for(int i=1;i&lt;=C;i++)&#123; position[i] = new ArrayList&lt;&gt;(); &#125; for(int i=0; i&lt;N;i++)&#123; int c= in.nextInt(); for(int j=0; j&lt;c;j++)&#123; position[j].add(i); &#125; &#125; int count = 0; for(int i=1 ; i&lt;=C;i++)&#123; //手链是环形 if(position[i].get(0)+N-position[position[i].size()-1] &lt; M)&#123; count++; continue; &#125; for(int j=0;j&lt;position[i].size()-1;i++)&#123; if(position[i].get(j+1) - position[i].get[j] &lt; M)&#123; count++; break; &#125; &#125; &#125; System.out.println(count); &#125;&#125;]]></content>
      <categories>
        <category>笔试</category>
      </categories>
      <tags>
        <tag>字节跳动</tag>
        <tag>真题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引及其背后的数据结构支持]]></title>
    <url>%2F2019%2F08%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%8F%8A%E5%85%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[索引及其背后的数据结构支持索引索引是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键，尤其是当表中的数据量越来越大时。 数据库查询是数据库最主要的功能之一. 如果想要理解MySQL中索引是如何工作的，最简单的方法就是去看看一本书的“目录”部分：如果想在一本书中找到某个索引，一般会先看书的“目录”，找到对应的页码。 B-Tree和B+Tree目前大部分数据库系统及文件系统都采用B-Tree或者B+Tree作为索引结构。这是有一定原因的。首先介绍其数据结构。 B-Tree为了描述B-Tree，首先定义一条数据记录为一个二元组[key，data]，key为记录的键值，对应不同的数据记录，key是互不相同的。data为数据记录出key外的数据。那么B-Tree是满足下列条件的数据结构： d为大于1的一个正整数，称为B-Tree的度。 h为一个正整数，称为B-Tree的高度。 每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d. 每个叶子节点最少包含一个key和两个指针，最多包含2n-1个key和2d个指针，叶节点的指针均为null。 所有叶节点具有相同的深度，等于树高h。 key和指针互相间隔，节点两端是指针。 一个节点中的key从左到右非递减排列[非严格递增]。 所有节点组成树结构。 每个指针要么为null，要么指向另外一个节点。 如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v（key1），其中v(key1)为node的第一个key的值。(隐隐有点像二叉搜索树，左边比根节点小。右边比根节点大) 如果某个指针在节点node的最右边且不为null，则其指向节点的所有key大于v（keym），其中v(keym)为node的最后一个key的值。 如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)； 图为一个d=2的B-Tree示意图，d为2指的是每个指针有两个数据，20，49是大于15且小于56的。 B+TreeMySQL普遍使用B+Tree实现其索引结构。与B-Tree相比，B+tree有以下不同点： 每个节点的指针上限为2d而不是2d+1 内节点不存储data，只存储key；叶子节点不存储指针； 下面是一个简单B+Tree示意： 由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。 一般来说，B+Tree比B-Tree更适合外存储索引结构，具体原因与外存储器原理及计算机存取原理有关。 带有顺序访问指针的B+Tree一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。 如图所示，在B+Tree中的每个叶子节点增加一个指向相邻叶子节点的指针，这样就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4要查询key从18到49顶点所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提高了区间查询效率。 为什么使用B+Tree红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这是为什么呢？ 一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中中就要产生磁盘IO消耗，相对于内存存取，IO存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是查找过程中磁盘IO操作次数。 根据B-Tree的定义，可知检索一次最多需要访问h个节点，数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次IO就可以完全载入了。为了达到这个目的，在实际实现中还需要如下技巧： 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次IO； B-Tree中一次索引最多需要h-1次IO，根节点常驻内存，渐进复杂度O(h)=O(logdN).一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小，通常不超3. 综上所述，用B-Tree作为索引结构效率是非常高的。 而红黑树这种结构，h明显要深得多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用数据的局部性，所以红黑树的IO渐进复杂度为O(h),效率明显比B-Tree差很多。 除此之外，B+Tree更适合外存索引，原因和内节点出度d有关。由上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小。 由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。 MySQL索引实现不同存储引起对索引的实现方式是不同的，这里主要介绍MyISAM和InnoDB两个存储引擎的索引实现方式。 MyISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 这里假设表一共有三列，假设我们以col1为主键，则图8是一个MyISAM表的主索引示意。可以看出，MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在col2上建立一个辅助索引，则此索引的结构如下图所示： 注意看辅助索引的和主索引的差别，辅助索引叶子节点存放的key是辅助字段的值，而主索引叶子节点存放的key是主键的值。 因此MyISAM中索引检索的算法首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其data域的值，然后以data域的值为地址，读取相应的数据记录。 MyISAM的索引方式也叫做非聚集索引。 InnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但实现方式却与MyISAM截然不同。 第一个重大区别就是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据文件的地址。而在InnoDB中，表数据文件本身就是按B+tree组织的一个索引结构。这颗树的叶节点data域保存了完整的数据记录，这个索引的key是数据表的主键。 图10是InnoDB主索引(同时也是数据文件)的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键。如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。 第二个与MyISAM索引不同的是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。如下图所示： 聚集索引这种实现方式使得按主键搜索十分高效，但是辅助索引搜索需要检索两遍索引：通过辅助索引获得主键，然后用主键到主索引中检索获得记录。 了解不同存储引擎的索引实现对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是一个好主意，因为InnoDB数据本间本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 索引使用策略及优化MySQL的优化主要分为结构优化和查询优化。本章讨论的高性能索引策略主要属于结构化优化范围。 最长前缀原理与相关优化高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关。主键有三个emp_no, title, from_date. 情况一：全列匹配很明显，当按照索引中的所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。理论上索引对顺序使敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引。 情况二：最左前缀匹配当查询条件精确匹配索引的左边连续一个或几个列时，索引可以被用到，但是只用到一部分，即条件所组成的最左前缀。 情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引&lt;emp_no, from_date&gt;，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。 “填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。 情况四：查询条件没有指定索引第一列由于不是最左前缀，索引这样的查询显然用不到索引。 情况五：匹配某列的前缀字符串EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#39;10001&#39; AND title LIKE &#39;Senior%&#39;; 如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀。 情况六：范围查询范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。 情况七：查询条件中含有函数或表达式很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引(虽然某些在数学意义上可以使用)。由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。 索引选择性与前缀索引既然索引可以加快查询速率，是不是只要是查询语句就建上索引？答案是否定的，因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行中也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引： 第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描好了。至于多少条记录才算多，这个人有个人的看法，记录数不超过2000可以考虑不建索引，超过2000条才可以酌情考虑索引。 另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性是指不重复的索引值与表记录数的比值。显然选择性的取值范围为(0,1],选择性越高的索引价值越大，这是由B+Tree的性质决定。 有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时应为索引key变短而减少了索引文件的大小和维护开销。 前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身） InnoDB的主键选择与插入优化在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。 上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主机那将其插入到适当的节点和位置，如果页面到达装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。 这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。 如果使用非自增主键（如身份证或学号等）由于每次插入主键的值近似于随机，因此每次新记录都要被插到现有索引页的中间某个位置。 因此MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能被回写到磁盘上而从缓存中清掉，此时又要从磁盘中读回来。这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 因此，只要可以，请尽量在InnoDB上采用自增字段作为主键。 参考文献[1] MySQL索引背后的数据结构及算法原理]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>索引</tag>
        <tag>B+树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2019%2F07%2F24%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例Singleton确保一个类只有一个实例，并提供该实例的全局访问点。Singleton通常被用来代表那些本质上唯一的系统组件，比如窗口管理器或者文件系统。 使用一个私有构造函数，一个私有静态变量以及一个公有静态函数来实现。私有构造函数保证了不能通过构造函数来创建对象实例，只能通过公有静态函数返回唯一的私有静态变量。 最简单的单例实现：饿汉模式12345678910public class Singleton &#123; //类装载的时候已经初始化 private static final Singleton instance = new Singleton(); //构造器私有化 private Singleton()&#123; &#125; //提供公有的获取方法 public static Singleton getInstance()&#123; return instance; &#125;&#125; 这种实现方式虽然不是最好的实现方式，但是是最常用的单例的实现方式。因为类一开始即被装载，所以不用担心线程安全的问题。但是缺点就是如果不使用这个类，就会内存浪费的问题。 线程安全：双重检查模式加锁操作只需要对实例化部分的代码进行，只有当instance没有被实例化时，才需要进行加锁。 1234567891011121314151617public class Singleton &#123; //volatile的生命作用是内存变量共享，和禁止指令重排序 private static volatile Single instance; //构造器私有化 private Singleton()&#123;&#125; //提供公有的获取方法 public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized (Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 为什么在锁的内部还有再加一层if判断呢，如果只有一个if语句，在instance==null的情况下，如果两个线程都进入了if语句块中，虽然在if语句块中有加锁操作，但两个线程都会执行实例化instance= new Singleton()这条语句，只是时间问题。那么就会进行两次实例化。破话了单例模式。因此需要两个if语句：第一个语句用来避免instance已经被实例化后的加锁操作，第二个if语句进行了加锁，只有一个线程进入，不会出现多次实例化的情况。 静态内部类实现当Singleton类被加载时，静态内部类SingletonHolder没有被下载进内存。只有当调用getInstance()方法时从而触发SingletonHolder.instance时SingletonHolder才会被加载。此时初始化INSTANCE视力，并且JVM确保INSTANCE只能被实例化一次。 这种方式不仅具有延迟初始化的好处，而且由JVM提供了对线程安全的支持。 1234567891011public class Singleton &#123; private Singleton()&#123;&#125; //静态内部类不会在一开始被装载，所以没有内存消耗的问题 //JVM在装载静态内部类是线程安全的，只有在使用内部类才会去装载，所以线程是安全的 private static class SingletonHolder &#123; private static final Singleton INSTNCE = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; JVM装载内部类并不是程序启动就装载，而且装载内部类是线程安全的。所以这个单例模式真正意义上实现了懒加载与线程安全且节省了内存。 枚举实现实现单例模式只需编写一个包含单个元素的枚举类型： 12345public enum Singleton &#123; INSTANCE; public void updateInstance()&#123; &#125;&#125; 简洁，且无偿地提供了序列化机制，绝对防止多次实例化，即使是在面对复杂的序列化或者反射攻击的时候。可以防止反射攻击，防止反序列化重新创建新的对象。 参考资料[1] Effective Java 中文版 [2] 技术面试必备基础知识 [3] CodeSheep单例模式]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>单例模式</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署Java项目]]></title>
    <url>%2F2019%2F06%2F28%2FJava%E9%83%A8%E7%BD%B2%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[如何部署自己的项目在服务器上 主要是点来点去的。 一、登录服务器点击IDEA菜单栏的tools-&gt;Deplment，输入服务器的账号和密码，测试一下，查看是否连接成功。这里连接道康服务器，之前已经输入过账号和密码，连接成功。 tools-&gt;start SSH session,终端进入道康服务器。 输入指令ps aux | grep visualcensus过滤查找之前运行的进程号。 杀死之前的那个进程kill 1215，1215为上面查找的进程id。 二、打包当然要配合数据库，但是因为男神操作太快，这里就没能记录下来。 右侧边状态栏，点击Maven，在Lifecycle中点击package，将整个项目打包。等待打包完成。 三、上传直接将打包好的额target包下面的.jar文件用鼠标拖到Remote Host中的visualcensus中，在命令行输入nohup java -jar visualcensusserver-0.0.1-SNAPSHOT.jar &gt; /dev/null 2&gt;&amp;1 &amp;y运行java工程。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>deployment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24题一组数据交换相邻节点]]></title>
    <url>%2F2019%2F03%2F01%2F24%E9%A2%98%E4%B8%80%E7%BB%84%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2%E7%9B%B8%E9%82%BB%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[交换相邻节点 难度：中等 思路：递归 一、题目描述给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。 你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 示例: 1给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3. 二、问题分析链表中节点的交换是传统问题，两个指针解决问题，唯一要注意的是不能在交换过程中把链表给断开了，否则岂不是得不偿失？暴力法本可以解决一切，但是优雅的方法是递归，把相邻节点的交换搞定，然后递归把所有的节点串起来，简直是美滋滋啊。 三、代码分析12345678910111213141516171819class Solution: def swapPairs(self, head): # 防止只有一个节点或没有节点时报错 if head and head.next: p = head q = head.next head = q # 第一次交换不需要考虑与前面的连接 三步法连接 p.next = q.next q.next = p # 开始递归 p.next = self.swapPairs(p.next) else: if head: return head else: return None return head 复杂度分析 O(N)]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>链表</tag>
        <tag>交换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23题合并k个有序的链表]]></title>
    <url>%2F2019%2F03%2F01%2F23%E9%A2%98%E5%90%88%E5%B9%B6k%E4%B8%AA%E6%9C%89%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[合并K个有序的链表 难度： hard模式 思路：优先级队列 一、题目描述合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 示例: 1234567输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 二、问题分析首先是hard模式，说明不能轻易的解决这个问题。认真思考了一个小时，觉得已经理清楚思路，然而苦于不知该如何实现自己的思路。试了几种方法，反而是原地打转，于是决定参考一下答案。答案实现了我的思路，原来使用了一种之前没有用过的数据结构，优先级队列(PrivirotyQueue),这一篇专栏简单介绍了优先级队列，对于理解这题，简直是正中靶心。 思路如下： 用三个指针指向k个链表的头部，比较指针中的值，将最小的值加入到结果中，然后指针后移，直到所有的指针为空。由于是列表，无法直接得到所有链表的头部，所以只能通过优先级队列来做。遍历列表，将头指针和头指针的val组成一个元组入队列，出队列时头指针的val作为评判其优先级的标准。注意事项，当队列中的元组优先级(即头指针的val)相同时，将会把指针这个对象作为比较优先级的评判标准，但是对象在python中是不能直接比较的，会引起代码崩溃，元组之间的元素用逗号隔开，不能有空格，否则代码也会崩溃。 三、代码分析123456789101112131415161718192021222324from queue import PriorityQueue as PQ# 导入优先级队列的包class Solution: def mergeKLists(self, lists): head = point = ListNode(0) pq = PQ() index = 0 for l in lists: if l: # 当列表的优先级相同(即val相等）时，由元祖中的第二个元素确定优先级， # 而链表是对象不能直接确定优先级，所以加入一个变化的下标作为优先级避免程序崩溃 pq.put((l.val,index,l)) index += 1 while not pq.empty(): val,index, node = pq.get() # 不能直接操作point，会导致链表的断裂 point.next = node point = point.next node = node.next if node != None: pq.put((node.val,index,node)) index += 1 return head.next 复杂度分析 O(N log k) :比较大小的时间花费将被减少到O(log k)，因为优先级队列的内部实现机制用到了堆，但是找到最小值的节点仅仅花费 O(1)， 在最终的链表中有K个节点。]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>优先级队列，链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21题有序链表的合并]]></title>
    <url>%2F2019%2F02%2F22%2F21%E9%A2%98%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[LeetCode刷题之21题有序链表的合并 难度：easy 思路：硬算 一、题目描述将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 12输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 二、问题分析有序链表的合并是归并排序中的经典算法，这题采用常规思路即可解决问题，唯一要注意的点是当指针p、q中任一指针为空时后续应该如何操作。 三、代码分析1234567891011121314151617181920212223242526272829303132333435def mergeTwoLists(self, l1, l2,): p = l1 q = l2 head = None # p q均不为空 while p != None and q != None: if p.val &lt;= q.val : if head == None: head = p n = p p = p.next else: n.next = p n = n.next p = p.next else : if head == None: head = q n = q q = q.next else: n.next = q n = n.next q = q.next # p q中任一为空 将p指定为非空 直接将p后面的节点连在n的后面 if p == None and q !=None: p = q q = None if head == None: head = p n = p else: n.next = p return head 时间复杂度分析： O(M+N) M为l1链表的长度，N为l2链表的长度]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题之20题有效的括号]]></title>
    <url>%2F2019%2F02%2F22%2F20%E9%A2%98%E6%8B%AC%E5%8F%B7%E7%9A%84%E9%85%8D%E5%AF%B9%2F</url>
    <content type="text"><![CDATA[LeetCode刷题之20题有效的括号 难度：简单 思路：栈 一、题目描述给定一个只包括 &#39;(&#39;，&#39;)&#39;，&#39;{&#39;，&#39;}&#39;，&#39;[&#39;，&#39;]&#39; 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。 示例： 12输入: "&#123;[]&#125;"输出: true 二、问题分析这是一题难度为简单的题，但我仍旧很久没有思路，就是没有想到利用栈的特性，本题是一道经典的栈的特性的题目，想到栈，就成功了一大半。 三、 代码分析123456789101112131415161718192021222324def isValid(self, s): res = True stack = [] for element in s: if not stack: # 栈为空 stack.append(element) # 利用栈的先进后出的特点，判断列表的尾部即栈的头部的元素情况 elif stack[-1] == '(' and element == ')': stack.pop() # 出栈在栈的头部 elif stack[-1] == '[' and element == ']': stack.pop() elif stack[-1] == '&#123;' and element == '&#125;': stack.pop() else: stack.append(element) # 进栈也在栈的头部 # 判断栈是否为空，为空则说明括号是对称有效 if stack : res = False else : res = True return res 复杂度分析： O(N) N为字符串的长度]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19题删除链表的指定节点]]></title>
    <url>%2F2019%2F02%2F18%2F19%E9%A2%98%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E5%80%92%E6%95%B0N%E7%9A%84%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[删除链表的指定节点 难度：中等 思路：窗口法 一、问题描述给定一个链表，删除链表的倒数第n个节点，并且返回链表的头结点。 示例： 给定一个链表：1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2. 当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5. 说明：给定的n保证是有效的。 进阶：你能尝试一趟扫描实现吗？ 二、问题分析2.1 逻辑梳理本题和链表有关，链表是最基本的数据结构，链表中的元素可存储在内存的任何地方，链表的每个元素都存储了下一个元素的地址，从而使一系列随机的内存地址串在一起。链表的优势在于插入和删除元素，可以快速完成而不需要移动其他元素。链表由一个个节点组成，节点有两部分，节点的值和下一个节点的地址，尾节点的下一个节点的地址为空。在Python中即None，想要通过一趟扫描删除倒数第n个节点，最有效的方法就是窗口法，指针p，q之间间隔n个节点，然后指针p、q同步往尾部移动，当q到达尾节点时，p后的节点即我们需要删除的目标节点。将p内节点的地址指向下下个节点，删除目标节点，任务完成。 2.2 难点分析函数传进来的参数和传出去的值都是头结点，在删除节点时，有一个问题需要考虑，怎么保证下下个节点是存在的，如果恰好要删除的就是头节点，是否在程序中考虑到了？其实我刚开始也没考虑，就把示例传进去有正确结果返回高兴的屁颠屁颠以为自己做完了，但上传上去之后被特殊情况搞得晕头转向，仔细分析了很长时间才把head、p、q之间的关系理清楚。 三、代码分析12345678910111213141516171819def removeNthFromEnd(self, head, n): if head: p=head q=head # 构建窗口，保证p、q指针之间间隔n个节点 while n&gt;0 and q != None: #当循环结束，如果q=None，则说明需要删除的是头结点。 q = q.next n -= 1 if q != None:#需要删除的节点不是头结点，p、q正常往链表尾部滑动 while q.next != None : p = p.next q = q.next if q == None : #要删除头节点 head = p.next else: p.next = p.next.next #正常情况 删除p后面的节点 return head 复杂度分析： O(N) N为链表的节点个数]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>链表</tag>
        <tag>窗口法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18题四个数的求和]]></title>
    <url>%2F2019%2F02%2F18%2F18%E9%A2%98%E5%9B%9B%E4%B8%AA%E6%95%B0%E7%9A%84%E5%92%8C%2F</url>
    <content type="text"><![CDATA[四个数的和 难度：中等 思路：头尾逼近法 一、问题描述给定一个包含n个整数的数组nums和一个目标值target，判断nums中是否存在四个元素a，b，c，和d，使得a+b+c+d的值与target相等？找出所有满足条件且不重复的四元组。 注意：答案中不可以包含重复的四元组。 示例： 给定数组nums=[1, 0, -1, 0, -2, 2], 和target=0。 满足要求的四元组集合为： [[-1 ,0, 0, 1], [-2, -1, 1, 2], [-2 ,0, 0, 2]] 二、问题分析在LeetCode的题目顺序有一个由浅入深的过渡，这题的解决方法完全可以参照三个数的求和问题。让我们来回顾一个三个数的求和问题，三个数的求和与四个数的求和表面上是一模一样的，无非是把三个数替换为四个数，所以在解决方式上内核机制也是相同的。 2.1 排序数的求和问题，最简单粗暴的方法就是把给定的数组for循环遍历几次，找到所有符合要求的数，但是因为时间开销过大，提交的时候不被通过，所以只能找其他的渠道。第一步，将所给的数按照从小到大排序，Python有内置的排序函数，这里就直接调用了。 2.2 开始遍历在多个数求和问题中，使用的方法为两头法，具体实现方法如下。首先固定第一个数，从数组的头部开始，求出目标数target与第一个数的差值diff；然后固定第二个数，求出之前的差值diff与当前数的差值作为新目标goal；然后使用头尾法，如果头尾的和小于goal，则头往后移，如果头尾的和大于goal，则尾往前移（经过排序后，尾部的数大头部的数小），如果头尾的和正好等于goal，那么我们找到了目标数，把四个数存到结果中，同时往中间移动头尾的坐标，头尾位置下标相等时此次遍历结束；然后依次移动前两个固定的数。 2.3 难点分析这题确定了算法，还是有很多细节需要推敲，而这些细节有些时候比算法本身更花时间。在题目描述中，它特地提出让我们注意解决重复元素的问题，解决重复问题有两个思路：一是处理返回的数组，将其中重复的元素去掉；二是从源头上解决问题，在生成结果数组时，一旦发现重复就不再添加入返回数组。这题真正的难点就在这里了，怎么样才能最有效的去除重复元素呢？这里只提供一个巧妙的思路，重复的元素从何而来，归根结底是因为数组中本身就有重复的元素，在求和的时候，当我们移动到下一个元素的时候，检测当前元素与上一个元素是否相等，这里为什么是与前一个元素作比较而不是与后一个元素作比较，这是有原因的，如果与后一个元素作比较的话，那么就会漏掉一种情况，这两个数相等但是他们的和就是我们想找的，如果与后一个元素作比较的话这个数还没有参与计算就会被跳过。结果会错误。（注意，当我们访问一个元素的时候要确保这个元素存在否则就会报错），如果相等就跳过此次循环。（需要确保每个不重复元素都被访问到） 2.4 细节首先要对输入的数组进行长度判断，避免输入空数组时后续进行不存在位置的的访问导致程序崩溃；其次是重复元素的问题，在元素移动过程中，为了不产生重复的四个数组合，固定的第一个数往后移动时，需要考虑当前数与上一个数是否相等，如果相等，则使用continue语句跳过此次循环。固定的第一个数也存在一模一样的问题。其次是首尾移动时，当检测到首尾之和相等时，头部和尾部的位置都往中间移，这时头尾分别与后一个数作比较，如果相等的话，头尾坐标继续往中间靠。（这里检测到头尾之和与目标相等时，不存在一个数还没用到就被丢弃，所以可以与后一个数作比较） 三、代码分析1234567891011121314151617181920212223242526272829303132def fourSum(self, nums, target): res=[] nums=sorted(nums) #排序 length=len(nums) if length &lt; 4: return res for i in range(0, length-3): diff=target-nums[i] if i &gt;0 and nums[i-1] == nums[i]: #防止重复 continue for j in range(i+1, length-2): goal=diff-nums[j] front=j+1 back=length-1 if j &gt;i+1 and nums[j-1] == nums[j]:#防止重复 continue while front&lt;back: the_sum=nums[front]+nums[back] if the_sum &lt; goal: front += 1 if the_sum &gt; goal: back -= 1 if the_sum == goal: res.append([nums[i], nums[j], nums[front],nums[back]]) while front &lt;back and nums[front] == nums[front+1]:#防止重复 front+=1 while front &lt; back and nums[back]==nums[back-1]:#防止重复 back -=1 front += 1 back -= 1 return res 复杂度分析： 耗时还是非常多的，排序+O(N^3^)。]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>求和</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17题电话号码的字母组合]]></title>
    <url>%2F2019%2F02%2F18%2F17%E9%A2%98%E7%94%B5%E8%AF%9D%E5%8F%B7%E7%A0%81%E7%9A%84%E5%AD%97%E6%AF%8D%E7%BB%84%E5%90%88%2F</url>
    <content type="text"><![CDATA[电话号码的字母组合 难度：中等 思路：递归 一、题目描述给定一个仅包含数字2-9的字符串，返回所有它能表示的字母组合。 给出数字到字母的映射如下（与电话按键相同）。注意1不对应任何字母。 示例： 输入：“23” 输出：[“ad”, “ae”, “af”, “bd”, “be”, “bf”, “cd”, “ce”, “cf”] 二、解题过程拿到这个题目，分析我们要解决的问题，题目给出了数字到字母的映射，故首先要把映射关系一一对应出来，在Python中很容易想到字典，把映射关系先存起来，唯一值得推敲的是这里的值的类型是存成字符串&quot;abc&quot;还是数组[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]呢？看到电话按键我们很容易想到字符串，但研究我们最终的输出结果类型，存为数组类型更方便后边的计算，如下： 1234dict_map = &#123;'2':['a','b','c'], '3':['d','e','f'], '4':['g','h','i'], '5':['j','k','l'], '6':['m','n','o'], '7':['p','q','r','s'], '8':['t','u','v'], '9':['w','x','y','z']&#125; 第二步来到了怎么解决这个题目，这个题目看起来很简单，实际上也很简单但就需要那么灵光一现，首先把它的结构图画出来，本质上是一个全组合问题，通过for循环遍历给出的数字所对应的字母，然后内部嵌套for循环遍历下一个数字对应的字母，就这样层层嵌套，唯一的难点是我们无法提前预知需要嵌套多少层for循环。 灵光乍现了，递归函数能够很好的解决这种循环问题。通过认真分析，发现这题用递归是最棒的方法。首先来复习一下递归： 递归将问题分解为越来越小的子问题，直到问题的规模小到可以被直接解决。每个递归函数都有两个部分：基线条件和递归条件 。递归条件指的是函数调用自己，而基线条件是指函数不再调用自己，从而避免无限循环。 如果你还对递归算法有疑问的话，试着写一个关于某个数阶乘的递归算法，fact(n) return n*(n-1)*(n-2)...规定0！=1，最合适的基线条件什么呢？ 分析此题，基线条件可以是待访问的数字个数为1时，返回这个键的映射值；递归条件为访问当前访问数字的第一个数字，然后for循环遍历这个数字对应的字母，在for循环内部，将数字的第一位去掉然后调用函数本身。然后for循环遍历返回值。 完整代码如下： 12345678910111213141516171819class Solution: def letterCombinations(self, digits): dict_map = &#123;'2':['a','b','c'], '3':['d','e','f'], '4':['g','h','i'], '5':['j','k','l'], '6':['m','n','o'], '7':['p','q','r','s'], '8':['t','u','v'], '9':['w','x','y','z']&#125; res = [] if len(digits) : if len(digits) == 1: return dict_map[digits[0]] else: first = dict_map[digits[0]] for x in first: second = self.letterCombinations(digits[1:]) for y in second: t = x + y res.append(t) return res return res]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派控制红外遥控]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E6%8E%A7%E5%88%B6%E7%BA%A2%E5%A4%96%E9%81%A5%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[树莓派控制红外遥控 写在前面：因项目需要，故在网上淘了一个红外遥控模块，在树莓派上学习一下红外遥控。 一、红外遥控及接线​ 38K通用红外遥控器，采用NEC编码格式，传输距离大于八米，比较适合日常开发，使用方便。 ​ 红外接收模块引脚说明：S为OUT引脚，中间为VCC，-为GND。根据模块上的标识来接。 ​ 插到树莓派上，S接树莓派的12引脚（物理引脚编码），其BCM编码为18；VCC接3.3V；GND接树莓派任意GND引脚即可。模块实拍如下图所示： 二、软件配置2.1 安装lirc，修改配置文件​ LIRC（Linux Infrared remote control）是一个Linux系统下开源的软件包，用来从远程通用红外设备上接收和发送红外信号。可以解码和发送红外信号。 ​ 通过SSH连接树莓派，安装lirc： 1sudo apt-get install lirc ​ 因为lirc版本更新的原因，不同的版本修改的配置文件不同，输入lircd -v查看lirc的版本，我是0.9.4.c，修改/etc/lirc/lirc_options.conf文件，用vi进入修改： 123[lircd]# driver = devinputdriver = default 2.2 修改/boot/config.txt​ 用vi进入文件内部，找到dtoverlay并修改如下： 1dtoverlay=lirc-rpi,gpio_in_pin = 18 ​ 这里18对应树莓派BCM编码的gpio接口。 2.3 重新开启lirc12sudo /etc/init.d/lircd restartsudo modprobe lirc_rpi 至此，lirc软件配置完成 三、测试红外接收3.1关闭红外接收功能命令行输入以下命令，关闭lirc： 1sudo kill $(pidof lircd) 3.4 测试红外接收1mode2 -d/dev/lirc0 用红外遥控器，对着接收器按下任意按键，屏幕会打印类似下面的内容，说明红外接收功能正常。 1234space 562pulse 579space 1672pulse 577 在这里我卡壳了，接收不到任何内容，反复检查了前面的步骤，确定无误后继续谷歌，找到了这篇博客^1，之前输出随意找了一个IO口，但是都没有用，把OUT连接到GPIO pin12上，然后执行 1sudo dmesg | grep -i lirc 发现有内容了，怀疑是红外遥控的输出引脚有指定。 3.5 红外编码录制首先查看有哪些按键名并记录，输入： 1sudo irrecord --list-namaspace 我用的几个键名是： 按键 按键名 1 KEY_1 2 KEY_2 3 KEY_3 4 KEY_4 5 KEY_5 6 KEY_6 7 KEY_7 8 KEY_8 9 KEY_9 0 KEY_0 * KEY_STAR # KEY_PUND ↑ KEY_UP ↓ KEY_DOWN ← KEY_LEFT → KEY_RIGHT OK KEY_OK 执行红外线编码录制命令： 1sudo irrecord -d /dev/lirc0 ~/lircd.conf 刚开始需要输入文件名称，最终会根据此名称保存对应的文件名，我的文件名为pi-key，然后会有一堆英文提示出来，继续回车，会让你按按键，每个按键保证屏幕上输出一个.,一直按保证所有的按键都被按到，全部按过一遍之后就不停的按最后按的那个按键 然后就会弹出第二轮按键录入，这时也是不停按，要有耐心，循环按，使劲按，直到弹出需要你输入下一个按键的名字为止。如下： 这时依次录入按键名字，然后按下对应的按键，输入按键名字不能输删除，如果输错了也不要紧，按回车重新输入即可。将所有的按键都录入，这一步就结束了。成功之后会在~/目录下生成pi.lircd.conf这个文件，把这个文件放到/etc/lirc/lircd/lircd.conf.d/这个目录里即可，命令行输入： 1sudo cp ~/pi.lircd.conf /etc/lirc/lircd.conf.d/ 完成后重启树莓派。 四、运行Python代码运行编写的Python代码，终端会显示按键的键值。 Python代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!/usr/bin/python#-*-coding:utf-8-*-import RPi.GPIO as GPIOimport timefrom Constants import KeysPIN = 18delay_time = 0.00006GPIO.setmode(GPIO.BCM)GPIO.setup(PIN, GPIO.IN, GPIO.PUD_UP)print("irm test start...")def exec_cmd(key_val): if(key_val==Keys.KEY_1): print("Button KEY_1") elif(key_val==Keys.KEY_2): print("Button KEY_2") elif(key_val==Keys.KEY_3): print("Button KEY_3") elif(key_val==Keys.KEY_4): print("Button KEY_4") elif(key_val==Keys.KEY_5): print("Button KEY_5") elif(key_val==Keys.KEY_6): print("Button KEY_6") elif(key_val==Keys.KEY_7): print("Button KEY_7") elif(key_val==Keys.KEY_8): print("Button KEY_8") elif(key_val==Keys.KEY_9): print("Button KEY_9") elif(key_val==Keys.KEY_0): print("Button 0") elif(key_val==Keys.KEY_STAR): print("Button KEY_STAR") elif(key_val==Keys.KEY_POUND): print("Button KEY_POUND") elif(key_val==Keys.KEY_UP): print("Button KEY_UP") elif(key_val==Keys.KEY_LEFT): print("Button KEY_LEFT") elif(key_val==Keys.KEY_OK): print("Button KEY_OK") elif(key_val==Keys.KEY_RIGHT): print("Button KEY_RIGHT") elif(key_val==Keys.KEY_DOWN): print("Button KEY_DOWN") try: while True: if GPIO.input(PIN) == 0: count = 0 while GPIO.input(PIN) ==0 and count &lt;200: count +=1 time.sleep(delay_time) while GPIO.input(PIN) == 1 and count &lt; 80: count += 1 time.sleep(delay_time) idx = 0 cnt = 0 data = [0, 0, 0, 0] for i in range(0, 32): count = 0 while GPIO.input(PIN) ==1 and count &lt; 15: count += 1 time.sleeep(delay_time) count = 0 while GPIO.input(PIN) == 1 and count &lt; 40: count += 1 time.sleep(delay_time) if count &gt; 8: data[idx] |= 1&lt;&lt;cnt if cnt == 7: cnt = 0; idx +=1; else: cnt += 1 if data[0]+data[1] == 0xFF and data[2]+data[3] == 0xFF : print("Get the key: 0x%02x"%data[2]) exec_cmd(data[2])except KeyboardInterrupt: GPIO.cleanup(); 按下遥控按键，终端会显示接收到的按键的键值： 五、参考资料1、网址：https://iaiai.iteye.com/blog/2411532 2、产品说明书：https://pan.baidu.com/s/1E3tnY1Kzo_Sdkju7QzQylQ 3、网址：http://www.eeboard.com/bbs/thread-6940-1-1.html]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>树莓派</tag>
        <tag>红外遥控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo之NexT博客美化]]></title>
    <url>%2F2019%2F01%2F20%2FHexo%E4%B9%8BNexT%E5%8D%9A%E5%AE%A2%E7%BE%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Hexo之NexT博客美化 写在前面：默认的hexo界面看起来还是太简陋了，可以给Hexo换一个主题，这里推荐NexT，这是一个比较成熟的主题，使用的人也是最多的，优化，配置扩展都集成了，使用起来比较简单。然后再对功能界面做一些扩展，博客重质量，界面做的干净、清爽就行。本文详细介绍了博客美化的步骤。 一、安装NexT主题在命令行输入 1git clone https://github.com/theme-next/hexo-theme-next themes/next 下载主题。打开根目录下的_config.yml为博客的站点配置文件，主题配置文件在./themes/_config.yml。本文的整个配置基本是在修改这两个配置文件，所以你需要区分清楚。在站点配置文件./config.yml查找theme并修改： 12## Themes: https://hexo.io/themes/theme: next 这样就启用了主题next，可以输入hexo s查看效果。注意，有时候通过hexo s预览时，你会发现自己所做的修改并没有生效，这时不要着急，命令行输入hexo clean清理下database文件夹和public文件夹即可。 二、博客设置需要先对博客基本信息做一些设置，注意，设置时冒号后面都要有一个空格，这是yml语法格式。否则会报错或修改不生效。 2.1、设置语言在站点配置文件./_config.yml中，将language设置成所需要的语言。例如简体中文，配置如下： 1language: zh-CN 2.2、基本信息配置在站点配置文件./_config.yml的开头，填上自己博客的相应信息： 12345title: #标题subtitle: #子主页标题 description: #描述keywords: #关键字author: #作者zhen 2.3、设置主题的SchemeNext自带了几种外观，在主题配置文件./themes/next/_config.yml里找到schemes，可以自行选择布局，根据个人喜好，把前面的注释符#去掉即可： 12345# Schemes# scheme: Musescheme: Mist#scheme: Pisces#scheme: Gemini 2.4、菜单栏设置在网站首页有归档等菜单，在主题配置文件./themes/next/_config.yml里找到menu，把需要的菜单取消注释。另外也可以自己添加菜单栏，||后面是font awesome图标栏，如下： 123456789menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 2.5、创建页面设置完菜单但是没有相关页面的话点击进去就会显示错误。在命令行输入 123hexo new page tagshexo new page categorieshexo new page about 然后在./source/_posts文件夹下面会生成对应的文件夹，打开将页面的type设置为相应的内容。例： 123456---title: 这里是所有分类的汇总categories: 分类名 type: "categories"date: 2019-01-17 15:29:31--- 2.6、文章显示设置默认首页的文章会显示全文，在发表文章的内容中加上&lt;!--more--&gt; 这样首页中文章会显示到你插入这句话的前面，点击阅读全文才会显示整篇文章。 2.7、使用RSS在命令行中输入: 1npm install --save hexo-generator-feed 安装插件，然后在主题配置文件./themes/next/_config.yml中找到rss并修改： 1rss: /atom.xml 2.8、设置博客favicon图标在./themes/next/source/images目录下放置图标，和默认的图标类似，然后在主题配置文件./themes/next/_config.yml找到favicon并修改： 1234567favicon: small: /images/favicon-16x16-next.ico medium: /images/favicon-32x32-next.ico apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 2.9、侧边栏社交链接在主题配置文件./themes/next/_config.yml找到social把需要的内容取消注释，填好你的链接就可以。||后面的是图标名称，和菜单一样，也是使用的Font Awesome`图标。 123456789101112social: GitHub: https://github.com/zhengirl || github #E-Mail: mailto:yourname@gmail.com || envelope #Weibo: https://weibo.com/yourname || weibo #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype 2.10、设置背景动画在主题配置文件中，找到canvas_nest，改为true： 1234567canvas_nest: enable: true onmobile: true # display on mobile or not color: '0,0,255' # RGB values, use ',' to separate opacity: 0.5 # the opacity of line: 0~1 zIndex: -1 # z-index property of the background count: 99 # the number of lines 2.11、修改文章底部的#号标签打开./themes/next/layout/_macro/post.swig文件中，搜索rel=&quot;tag&quot;&gt;#,将#替换为Font Awesome图标： 1rel="tag"&gt;&lt;i class="fa fa-tag"&gt;&lt;/i&gt; 2.12、搜索服务在命令行输入： 1npm install hexo-generator-searchdb --save 安装hexo-generator-searchdb插件，然后在站点配置文件./_config.yml添加以下代码： 123456# searchsearch: path: search.xml field: post format: html limit: 10000 然后在主题配置文件./themes/next/_config.yml中找到local_search改为true即可： 12local_search: enable: true 2.13、代码高亮在站点配置文件./_config.yml内找到highlight，并设置如下： 123456highlight: enable: true line_number: true #代码自动高亮 auto_detect: true tab_replace: 然后在主题配置文件./themes/next/_config.yml中找到highlight_theme，设置成你喜欢的代码高亮主题： 1234# Code Highlight theme# Available values: normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: night 2.14、头像圆形和旋转将头像显示成圆形，鼠标放上去有旋转效果，在.\themes\next\source\css\_common\components\sidebar\sidebar-author.styl文件将里面的内容替换为： 12345678910111213141516171819202122232425262728293031323334.site-author-image &#123; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; transition: 1.4s all;&#125;.site-author-image:hover &#123; background-color: #e6be93; -webkit-transform: rotate(360deg); -moz-transform: rotate(360deg); -ms-transform: rotate(360deg); -transform: rotate(360deg);&#125;.site-author-name &#123; margin: $site-author-name-margin; text-align: $site-author-name-align; color: $site-author-name-color; font-weight: $site-author-name-weight;&#125;.site-description &#123; margin-top: $site-description-margin-top; text-align: $site-description-align; font-size: $site-description-font-size; color: $site-description-color;&#125; 2.15、添加文章字数和阅读时长统计功能首先需要在命令行输入： 1npm install hexo-symbols-count-time --save 安装统计插件，然后在站点配置文件./_config.yml末尾添加如下使能统计功能的代码： 123456# reading timesymbols_count_time: symbols: true time: true total_symbols: true total_time: true 2.16、保留文章本身的编号我们在写博客的时候，会自己给文章编号，但next主题默认的也有编号，这样多个编号就比较奇怪，所以把默认的编号取消，在主题配置文件查找toc，修改如下： 1234toc: enable: true # Automatically add list number to toc. number: false 2.17、自定义博客Next中留出给使用者自我设计的空间，在/themes/next/source/css/_custom/cutom.styl文件中可以自行添加一些小样式让博客有所不同： 123456789//文章阴影与边缘强化.post &#123; margin-top: 0px; margin-bottom: 0px; border-radius: 16px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(0, 0, 0, 0.70); -moz-box-shadow: 0 0 5px rgba(0, 0, 0, 0.70);&#125; 三、在文章中显示图片首先在站点配置文件中将post_asset_folder后面修改为true，在建立一篇新的博客时，Hexo会自动建立一个与文章同名的文件夹，这样一来，就可以把图片存储在这个文件夹中方便调用。 其次本人习惯于在typora中将markdown文件编辑好之后直接复制到hexo中，所以需要对typora的设置做一些更改，打开偏好设置，选择将图片复制到指定文件夹中，这样在typora中也有指定的与文章同名的文件夹，所以将文章和文件夹都复制到Hexo中即可。 在命令行输入 1npm install https://github.com/CodeFalling/hexo-asset-image --save 安装插件，等待一段时间。输入hexo s在本地预览网站图片就可以显示啦！ 四、致谢在搭建博客的过程中，遇到了一些问题，参考了很多大佬的解决方案，感谢他们的分享。本文只是将自己搭建博客的过程复述了一遍，希望对后来者有所帮助。 推荐在配置的时看官方文档：http://theme-next.iissnan.com/third-party-services.html]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>美化设置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub搭建个人博客]]></title>
    <url>%2F2019%2F01%2F20%2FHexo%2BGitHub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Hexo+GitHub搭建个人博客author：刘真真 写在前面：去年三月份时候阿里云做活动就申请了一个域名，但是一直觉得搭建网站是一个比较麻烦的时候，就搁置了很久，在男朋友的鼓励下，遂决定好好捯饬一下自己的网站拿来写博客，开始一直担心自己做不出比较好的效果，后面渐渐将这种想法搁置，网上有非常多hexo的爱好者将自己的过程分享出来，基本上踩得坑都是前人遇到的，前人栽树后人乘凉，我也将搭建博客中一些关键性的步骤总结一下，以防后人跳坑。本人没有接触过前端知识，全凭谷歌和百度，所以有搭建个人网站想法的同学尽管去做，开始了第一步，后面的就不是问题了。 一、前期准备1.1、安装Node.js在Node.js官网下载对应平台的安装程序。在Windows上安装时需选择全部组建，勾选Add to Path,打开命令行安装成功可以看到 1.2、安装git在Git官网上下载Windows的安装程序。安装完成后，在开始菜单里找到”Git bsah Here”,弹出一个类似命令行的窗口，说明Git安装成功！ 同时配置电脑的环境变量，或者在安装的时候选择use Git from the Windows Command Prompt,即可在命令行中调用git。 1.3、Github账户注册和新建项目项目必须要遵守格式：账户名.github.io，以免后面产生不必要的麻烦。 1.4、安装hexo在电脑的任何位置建一个文件夹，我在E盘建了一个与工程同名的zhengirl.github.io文件夹，然后通过命令行进入该文件夹： 输入npm install hexo -g,开始安装hexo，输入hexo -v,检查hexo是否安装成功。 输入hexo init,初始化文件夹。经过漫长的等待，可以看到Start blogging with Hexo！。 输入npm install，安装所需要的组件。 二、本地网页的搭建2.1、体验hexo在安装好前面需要的一系列包后，输入hexo g，首次体验Hexo。 输入hexo s，开启服务器，访问该网址，正式体验Hexo。 2.2、将Hexo与github page联系起来首先需要设置Git的user name和email（如果是第一次使用的话）。打开命令行 12$ git config --golbal user.name. &quot;author&quot; #将用户名设为author$ git config --global user.email &quot;author@corpmail.com&quot; #将用户邮箱设为author@corpmail.com 添加SSH，详情见这篇博客,输入ssh -T gi@github.com,测试添加ssh是否成功。如果看到Hi后面是你的用户名，就说明成功了。 2.3、配置Deployment用VScode打开zhengirl.git.com.io,即整个工程，找到站点配置文件_config.yml，查找repo并修改，在文件末尾： 1234deploy: type: git repository: git@github.com:zhengirl/zhengirl.github.io.git branch: master 2.4、新建博客在命令行执行命令：hexo new post “博客名” 此时在/source/_posts下可以看到已经创建的文件 但这里则多生成了一个博客名的文件夹，至于为什么会生成这个文件夹以及它的用途，我们在下篇文章详解。 2.5、部署文章在生成以及部署文章之前需要安装一个扩展，npm install hexo-develoyer-git --save，编辑好文章后输入hexo d -g，生成和部署网站。 部署成功后访问网址：http://用户名.github.io,将看到部署成功的整个网站。 至此为止，最基本的hexo+github搭建个人博客基本完成，但是我们的博客还是太简陋了一些，接下来需要对博客进行一些雕琢。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>入门博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派入门]]></title>
    <url>%2F2019%2F01%2F18%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[树莓派入门（控制LED灯）author： 刘真真 写在前面：树莓派是基于Linux的迷你主机，但功能完善，且预留了很多IO口给开发者扩展，比单片机的功能强大不少，可以将Python程序移植到树莓派上。本文简单介绍了新手如何使用树莓派和利用树莓派点亮一个LED灯。 一、板载资源+配件树莓派是迷你主机，集成在一块电路板上。其型号为Rsspberry Pi 三代B型。 电源 ：Micro USB 接口的手机充电器，输出5V2A Micro SD卡 ：充当硬盘功能，大小最好在8G以上。 显示器：HDMI接口的显示器，需要屏幕则接 键盘：树莓派内置蓝牙，USB或蓝牙的无线键盘都可以用。需要时则配。 二、电子元件1、面包板 2、一段公头一端母头的杜邦线 3、LED二极管 4、1K的电阻 三、安装系统1、下载树莓派系统 网址: https://www.raspberrypi.org/downloads/ 选择需要的系统即可。这里我们选择树莓派官方的系统，预装了桌面和部分软件，如下图箭头所指。如果有一定的开源系统使用经验，可以选择最为轻量的只有操作系统的裸机。 2、将SD卡格式化 ​ 直接在文件资源管理器中将SD卡格式化即可 3、下载将系统导入内存卡的工具etcher 安装成功后打开，首先选择下载好的系统镜像文件，然后选择树莓派内存卡，点击Flash。 注意：在此过程中如果提示不可识别文件系统或者要格式化，直接点X关闭即可。 flash完成后，将内存卡取下插入树莓派，开机即可查看新系统！ 四、SSH登录安装系统之后，选择树莓派联网方式，树莓派有网线接口和WiFi芯片，用WiFi上网更加方便。在打开新系统时，搜索局域网输入密码即可。用SSH将电脑和树莓派系统连通，首先打开树莓派的SSH功能，在命令行输入： 1sudo raspi-config 得到如下的设置 进入第五项Interfacing Options，然后选择SSH： 使能SSH即可。电脑和树莓派连接同一个路由器，在浏览器访问路由器的IP（192.168.1.1），查看树莓派的IP地址为192.168.1.101。在客户端输入树莓派的用户名 pi 和密码 123456： 1ssh pi@192.168.1.101 与树莓派建立连接。 五、远程桌面为了更加方便地操作树莓派，安装远程桌面。打开树莓派终端，输入 1sudo apt-get install xrdp 等待安装完成。 打开电脑的远程桌面 输入树莓派的IP地址，远程桌面操作，用户名pi， 密码123456，连接成功： 六、点 亮 LED树莓派提供了一组通用IO口，称为GPIO。40个引脚的定义与板上引脚资源对应如下 将树莓派和电子元器件连起来。注意二级管的正负极。正极接3.3V，负极通过电阻接地，可以看到二极管亮了。下面使用Node脚本控制LED。 首先，将接地的导线从GND针脚拔出，接到GPIO0.0即11号引脚。注意，3.3V的针脚是是有标识的为方的，其他针脚都是圆的。代码如下： 1234567891011var rpio = require('rpio')rpio.open(11, rpio.OUTPUT)function blink()&#123; rpio.write(11, rpio.HIGH); setTimeout(function ledoff()&#123; rpio.write(11, rpio.LOW); &#125;,50);&#125;setInterval(blink, 100); 用node.js稍作尝试，接下来轮到主角python出场了，Linux系统中很多功能是通过python实现的，且内嵌了python，无需安装，与python的兼容性极好，所以尝试用Python使LED闪烁。 代码如下 1234567891011121314151617#!/usr/bin/python#author:lzzimport RPi.GPIO as GPIOimport timeGPIO.setwarnings(False)GPIO.setmode(GPIO.BOARD)#BCM和BOARD两种命名模式GPIO.setup(11, GPIO.OUT)while True: GPIO.output(11, GPIO.HIGH) time.sleep(0.05) GPIO.output(11, GPIO.LOW) time.sleep(0.05)GPIO.cleanup() 程序逻辑： 1、导入GPIO的包 2、导入与时间包 3、设置GPIO针的命名方式，可用的有GPIO.BCM和GPIO.BOARD，分别代表boardcom命名系统和树莓派板子上的命名系统。 4、将引脚11设置为输出 5、控制引脚11的电平高低变换 6、清除掉之前RPi.GPIO.setup()设置的状态。退出程序前一定要调用，否则下次调用会出错。]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>树莓派</tag>
        <tag>入门</tag>
        <tag>LED</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello,Hexo!]]></title>
    <url>%2F2019%2F01%2F17%2FHello-Hexo%2F</url>
    <content type="text"><![CDATA[使用hexo，是一件非常简单的事情。测试文本。]]></content>
  </entry>
</search>
